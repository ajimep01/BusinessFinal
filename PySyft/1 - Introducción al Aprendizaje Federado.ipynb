{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción al Aprendizaje Federado.\n",
    "\n",
    "\n",
    "### ¿Qué es el Aprendizaje Federado?\n",
    "\n",
    "Es una forma simple y poderosa de entrenar modelos. Si se piensa en los datos de entrenamiento,siempre son el resultado de algún tipo de proceso de recopilación. Las personas (a través de dispositivos) generan datos al registrar eventos en el mundo real. Normalmente, estos datos se agregan a una única ubicación central para que pueda entrenar un modelo de aprendizaje automático.\n",
    "\n",
    "En lugar de llevar los datos de entrenamiento al modelo (un servidor central), traes el modelo a los datos de entrenamiento (donde sea que se encuentren).\n",
    "\n",
    "La idea es que esto permite que quienquiera que esté creando los datos posea la única copia permanente, y así mantener el control sobre quién tiene acceso a ella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.1 - A Toy Federated Learning Example\n",
    "\n",
    "Para comprender exactamente que es el aprendizaje federado vamos a ver las diferencias entre esta técnica y la que se emplea habitualmente.\n",
    "\n",
    "Vamos a empezar entrenando un modelo de forma centralizada. \n",
    "Necesitamos:\n",
    "\n",
    "- Un dataset de prueba (Toy Dataset)\n",
    "- Un modelo\n",
    "- Lógica de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "hook = sy.TorchHook()\n",
    "from torch import nn, optim\n",
    "\n",
    "# A Toy Dataset\n",
    "data = sy.Var(sy.FloatTensor([[0,0],[0,1],[1,0],[1,1]]))\n",
    "target = sy.Var(sy.FloatTensor([[0],[0],[1],[1]]))\n",
    "\n",
    "# A Toy Model\n",
    "model = nn.Linear(2,1)\n",
    "\n",
    "def train():\n",
    "    # Training Logic\n",
    "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
    "    for iter in range(20):\n",
    "\n",
    "        # 1) erase previous gradients (if they exist)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # 2) make a prediction\n",
    "        pred = model(data)\n",
    "\n",
    "        # 3) calculate how much the missed\n",
    "        loss = ((pred - target)**2).sum()\n",
    "\n",
    "        # 4) figure out which weights caused us to miss\n",
    "        loss.backward()\n",
    "\n",
    "        # 5) change those weights\n",
    "        opt.step()\n",
    "\n",
    "        # 6) print our progress\n",
    "        print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.076326608657837\n",
      "1.768141746520996\n",
      "1.2177542448043823\n",
      "0.8632838129997253\n",
      "0.6180337071418762\n",
      "0.4457544684410095\n",
      "0.3236871063709259\n",
      "0.23652707040309906\n",
      "0.17383378744125366\n",
      "0.1284254640340805\n",
      "0.09532319754362106\n",
      "0.07104768604040146\n",
      "0.053148481994867325\n",
      "0.03988617658615112\n",
      "0.03001665510237217\n",
      "0.022643668577075005\n",
      "0.017117079347372055\n",
      "0.01296229474246502\n",
      "0.009830850176513195\n",
      "0.007465502247214317\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos entrenado un modelo básico de la manera convencional. Todos nuestros datos se agregan a nuestra máquina local y podemos usarlos para realizar actualizaciones en nuestro modelo. El aprendizaje federado, sin embargo, no funciona de esta manera. Entonces, modifiquemos este ejemplo para realizarlo con aprendizaje federado.\n",
    "\n",
    "Necesitamos:\n",
    "\n",
    "- crear un par de trabajadores.\n",
    "- Obtener los punteros para entrenar los datos en cada trabajador.\n",
    "- Lógica de entrenamiento actualizada para realizar aprendizaje federado. \n",
    "\n",
    "    Nuevos pasos de entrenamiento.\n",
    "    - Enviar el modelo al trabajador correcto.\n",
    "    - Entrenar con los datos localizados en ese trabajador.\n",
    "    - Traer de vuelta el modelo y repetir con el siguiente trabajador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a couple workers\n",
    "\n",
    "bob = sy.VirtualWorker(id=\"bob\")\n",
    "alice = sy.VirtualWorker(id=\"alice\")\n",
    "\n",
    "# get pointers to training data on each worker by\n",
    "# sending some training data to bob and alice\n",
    "data_bob = data[0:2].send(bob)\n",
    "target_bob = target[0:2].send(bob)\n",
    "\n",
    "data_alice = data[2:].send(alice)\n",
    "target_alice = target[2:].send(alice)\n",
    "\n",
    "# organize pointers into a list\n",
    "datasets = [(data_bob,target_bob),(data_alice,target_alice)]\n",
    "\n",
    "# Iniitalize A Toy Model\n",
    "model = nn.Linear(2,1)\n",
    "\n",
    "def train():\n",
    "    # Training Logic\n",
    "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
    "    for iter in range(20):\n",
    "        \n",
    "        # NEW) iterate through each worker's dataset\n",
    "        for data,target in datasets:\n",
    "            \n",
    "            # NEW) send model to correct worker\n",
    "            model.send(data.location)\n",
    "\n",
    "            # 1) erase previous gradients (if they exist)\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # 2) make a prediction\n",
    "            pred = model(data)\n",
    "\n",
    "            # 3) calculate how much the missed\n",
    "            loss = ((pred - target)**2).sum()\n",
    "\n",
    "            # 4) figure out which weights caused us to miss\n",
    "            loss.backward()\n",
    "\n",
    "            # NEW) get model (with gradients)\n",
    "            model.get()\n",
    "\n",
    "            # 5) change those weights\n",
    "            opt.step()\n",
    "\n",
    "            # 6) print our progress\n",
    "            print(loss.get().data[0]) # NEW) slight edit... need to call .get() on loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24732357263565063\n",
      "0.35474807024002075\n",
      "0.295735239982605\n",
      "0.1121668815612793\n",
      "0.1884697675704956\n",
      "0.06399760395288467\n",
      "0.11686219274997711\n",
      "0.038787536323070526\n",
      "0.07299670577049255\n",
      "0.023917512968182564\n",
      "0.046079330146312714\n",
      "0.014988611452281475\n",
      "0.02942308597266674\n",
      "0.009561199694871902\n",
      "0.0190159622579813\n",
      "0.006215935572981834\n",
      "0.012444151565432549\n",
      "0.004120749421417713\n",
      "0.008246853947639465\n",
      "0.002784881740808487\n",
      "0.005533907562494278\n",
      "0.0019166868878528476\n",
      "0.003758638398721814\n",
      "0.0013412302359938622\n",
      "0.0025824003387242556\n",
      "0.0009523084736429155\n",
      "0.001793382689356804\n",
      "0.0006845876341685653\n",
      "0.001257741474546492\n",
      "0.0004971838206984103\n",
      "0.0008899428066797554\n",
      "0.0003640666254796088\n",
      "0.0006346915615722537\n",
      "0.0002683281491044909\n",
      "0.00045581170707009733\n",
      "0.00019875857105944306\n",
      "0.0003293381887488067\n",
      "0.0001477920013712719\n",
      "0.00023921113461256027\n",
      "0.00011020559759344906\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¡FIN!\n",
    "\n",
    "Hemos entrenado un modelo de Aprendizaje Profundo muy simple utilizando el aprendizaje federado. Enviamos el modelo a cada trabajador, generamos un nuevo gradiente y luego devolvemos el gradiente a nuestro servidor local donde actualizamos nuestro modelo global. Nunca en este proceso hemos visto o solicitado acceso a los datos de entrenamiento subyacentes.Preservamos la privacidad de Bob y Alice.\n",
    "\n",
    "## Deficiencias de este ejemplo\n",
    "\n",
    "Entonces, aunque este ejemplo es una buena introducción al aprendizaje federado, todavía tiene algunas deficiencias importantes. En particular, cuando llamamos `model.get ()` y recibimos el modelo actualizado de Bob o Alice, podemos realmente aprender mucho sobre los datos de entrenamiento de Bob y Alice mirando sus gradientes. En algunos casos, podemos restaurar sus datos de entrenamiento perfectamente.\n",
    "\n",
    "¿Entonces, que hay que hacer? Bueno, la primera estrategia que se emplea es promediar el gradiente entre varias personas antes de cargarlo en el servidor central.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysyft",
   "language": "python",
   "name": "pysyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
